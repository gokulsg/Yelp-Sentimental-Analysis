import json
import sys
from sklearn import svm
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
import timeit

def load_data_from_file(filename):
    with open(filename) as infile:
        features = []
        labels = []
        num_data = 0
        num_pos_data = 0
        num_neg_data = 0
        data_size = 5000
        half_size = data_size / 2
        for line in infile:

            review = json.loads(line)
            if int(review['stars']) > 3:    # Positive
                if num_pos_data < half_size:
                    labels.append('1')
                    features.append(review['text'])
                    num_pos_data += 1
                    num_data += 1

            if int(review['stars']) < 3:    # Negative
                if num_neg_data < half_size:
                    labels.append('-1')
                    features.append(review['text'])
                    num_neg_data += 1
                    num_data += 1

            if num_pos_data + num_neg_data == data_size:
                # features = features_pos[0:1000] + features_neg[0:1000]
                print (len(features), len(labels), num_pos_data, num_neg_data)
                return features, labels

    return features, labels

if __name__ == '__main__':
    X, y = load_data_from_file(sys.argv[1])
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state=42)

    print(type(X_train))
    print(type(X_test))
    # Feature extraction

    vectorizer = TfidfVectorizer(min_df=3, max_df = 0.9, sublinear_tf=True, use_idf=True)                   #
    #vectorizer = CountVectorizer(min_df=5)
    #vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\b\w+\b', min_df=1)

    start = timeit.default_timer()
    train_vectors = vectorizer.fit_transform(X_train)
    test_vectors = vectorizer.transform(X_test)
    stop = timeit.default_timer()
    print(stop - start)

    # Classification (kernal=rbf)
    start = timeit.default_timer()
    classifier_rbf = svm.SVC(kernel='rbf', gamma=3.0)
    classifier_rbf.fit(train_vectors, y_train)
    prediction_rbf = classifier_rbf.predict(test_vectors)
    stop = timeit.default_timer()
    print(stop - start)

    print(len(prediction_rbf))
    print(len(y_test))

    tp = 0
    tn = 0
    fp = 0
    fn = 0
    for i in range (0, len(y_test)):
        if prediction_rbf[i] == y_test[i]:
            if prediction_rbf[i] == '1':
                tp += 1
            else:
                tn += 1
        else:
            if prediction_rbf[i] == '1':
                fp += 1
            else:
                fn += 1

    print(tp, tn, fp, fn, tp+tn+fp+fn)
    # Classification (kernel=linear)

    #start = timeit.default_timer()
    #classifier_linear = svm.SVC(kernel='linear')
    #classifier_linear.fit(train_vectors, y_train)
    #prediction_linear = classifier_linear.predict(test_vectors)
    #stop = timeit.default_timer()
    #print(stop - start)

    # Classification (kernel=linear)
    #start = timeit.default_timer()
    #classifier_liblinear = svm.LinearSVC()
    #classifier_liblinear.fit(train_vectors, y_train)
    #prediction_liblinear = classifier_liblinear.predict(test_vectors)
    #stop = timeit.default_timer()
    #print(stop - start)

    print("Results for SVC(kernel=rbf)")
    print(classification_report(y_test, prediction_rbf))
   
    #print("Results for SVC(kernel=linear)")
    #print(classification_report(y_test, prediction_linear))

    #print("Results for LinearSVC()")
    #print(classification_report(y_test, prediction_liblinear))
